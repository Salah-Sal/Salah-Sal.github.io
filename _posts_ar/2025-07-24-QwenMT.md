---
layout: post
title: "نموذج Qwen-MT لخدمة الترجمة الآلية من علي بابا"
date: 2025-07-24 10:00:00 +0300
lang: ar
categories: [ذكاء اصطناعي, ترجمة]
tags: [Qwen-MT, علي بابا, نماذج لغوية, ترجمة آلية, واجهة برمجة التطبيقات]
---

## **نموذج Qwen-MT لخدمة الترجمة الآلية من علي بابا**

Qwen-MT هو نموذج لغوي كبير مخصص للترجمة الآلية، قائم على نموذج Qwen. يدعم الترجمة بين 92 لغة (منها الصينية، والإنجليزية، واليابانية، والكورية، والفرنسية، والإسبانية، والألمانية، والتايلاندية، والإندونيسية، والفيتنامية، والعربية). كما يتيح نموذج Qwen-MT خصائص متقدمة مثل التدخل في المصطلحات، والتوجيه حسب المجال، وذاكرة الترجمة، وذلك لرفع جودة الترجمة في السياقات المعقدة.

### **النماذج المدعومة**

حُدِّث نموذج الترجمة الرائد تحديثًا شاملًا بالاعتماد على Qwen3، فأصبح يدعم 92 لغة (منها الصينية، والإنجليزية، واليابانية، والكورية، والفرنسية، والإسبانية، والألمانية، والتايلاندية، والإندونيسية، والفيتنامية، والعربية). وقد حُسِّن أداؤه تحسينًا ملحوظًا، فأضحى تخصيص المصطلحات فيه أكثر استقرارًا، وقدرته على حفظ التنسيق أعلى، وتكيفه مع المجالات المتخصصة أقوى، مع ترجمات أدق وأقرب إلى اللغة الطبيعية.

للحصول على أعلى جودة للترجمة، نوصي باستخدام نموذج **qwen-mt-plus**. أما إذا كانت السرعة أو التكلفة المنخفضة هي الأولوية، فنوصي بنموذج **qwen-mt-turbo**.

| الاسم | نافذة السياق (رمز مميز) | الحد الأقصى للمدخلات | الحد الأقصى للمخرجات | سعر المدخلات (لكل مليون رمز مميز) | سعر المخرجات (لكل مليون رمز مميز) | الحصة المجانية (ملحوظة) |
| :--- | :--- | :--- | :--- | :--- | :--- | :--- |
| **qwen-mt-plus** | 4,096 | 2,048 | 2,048 | 2.46 دولار أمريكي | 7.37 دولار أمريكي | مليون رمز مميز لكل منهما (صالحة لمدة 180 يومًا من تاريخ التفعيل) |
| **qwen-mt-turbo** | | | | 0.16 دولار أمريكي | 0.49 دولار أمريكي |

### **ملاحظات الاستخدام**

نظرًا لطبيعة الترجمة كحالة استخدام فريدة، يختلف نموذج Qwen-MT عن نماذج توليد النصوص العامة في الجوانب التالية:

*   يجب تمرير معاملات مثل اللغة المصدر (`source_lang`) واللغة الهدف (`target_lang`) باستخدام المُعامِل `translation_options`. إذا لم تكن متأكدًا من اللغة المصدر أو كان النص الأصلي يحتوي على لغات متعددة، فيمكنك ضبط قيمة `source_lang` على `auto`، وسيكتشف النموذج اللغة المصدر تلقائيًا.
*   للاطلاع على كيفية الاستخدام تحديدًا، انظر الشيفرة البرمجية في الأقسام التالية.
*   لا يدعم النموذج رسائل النظام (System Message) ولا المحادثات متعددة الجولات. يجب أن تحتوي مصفوفة `messages` على رسالة مستخدم (User Message) واحدة فقط، وهي النص المراد ترجمته.

### **المتطلبات الأساسية**

يجب أن تكون قد حصلت على مفتاح واجهة برمجة التطبيقات (API key) وهيأته كمتغير بيئة. إذا كنت تستخدم حزم تطوير البرمجيات (SDK) الخاصة بـ OpenAI أو DashScope لإجراء الاستدعاءات، فيجب تثبيت حزمة التطوير اللازمة أيضًا.

*   يجب أن يكون إصدار حزمة DashScope Java SDK هو 2.20.6 أو أحدث.

### **مثال بسيط**

فيما يلي مثال بسيط للترجمة من الصينية إلى الإنجليزية. بناءً على [اللغات المدعومة](#supported-languages)، اضبط قيمة المُعامِل `source_lang` على `Chinese` وقيمة `target_lang` على `English`. بعد ذلك، مرر النص المصدر `"我看到这个视频后没有笑"` إلى رسالة المستخدم (User Message). بعد إرسال الطلب، ستحصل على نتيجة الترجمة.

**نموذج الطلب**

```python
import os
from openai import OpenAI

client = OpenAI(
        # إذا لم تكن متغيرات البيئة مهيأة، فاستبدل السطر التالي بـ: api_key="sk-xxx"
        api_key=os.getenv("DASHSCOPE_API_KEY"),
        base_url="https://dashscope-intl.aliyuncs.com/compatible-mode/v1",
    )
messages = [
      {
        "role": "user",
        "content": "我看到这个视频后没有笑"
      }
    ]
translation_options = {
      "source_lang": "auto",
      "target_lang": "English"
    }
    
completion = client.chat.completions.create(
    model="qwen-mt-turbo",  # استخدام qwen-mt-turbo كمثال، ويمكنك تغيير اسم النموذج حسب الحاجة
    messages=messages,
    extra_body={
        "translation_options": translation_options
    }
)
print(completion.choices[0].message.content)
```

**نموذج الاستجابة**

```
I didn't laugh after watching this video. 
```
### **البث المتدفق (Stream)**

في وضع المخرجات المتدفقة، لا يولّد النموذج الاستجابة النهائية دفعة واحدة، بل يولّد نتائج وسيطة تدريجيًا، والتي يجب تجميعها لتكوين الاستجابة النهائية. يمكنك قراءة النص فور إخراجه من النموذج، مما يقلل من مدة انتظار استجابته.

**نموذج الطلب**

```python
import os
from openai import OpenAI

client = OpenAI(
        # إذا لم تكن متغيرات البيئة مهيأة، فاستبدل السطر التالي بـ: api_key="sk-xxx"
        api_key=os.getenv("DASHSCOPE_API_KEY"),
        base_url="https://dashscope-intl.aliyuncs.com/compatible-mode/v1",
    )
messages = [
      {
        "role": "user",
        "content": "我看到这个视频后没有笑"
      }
    ]
translation_options = {
      "source_lang": "Chinese",
      "target_lang": "English"
    }
    
completion = client.chat.completions.create(
    model="qwen-mt-turbo",  # استخدام qwen-mt-turbo كمثال، ويمكنك تغيير اسم النموذج حسب الحاجة
    messages=messages,
    stream=True,
    extra_body={
        "translation_options": translation_options
    }
)
for chunk in completion:
    print(chunk.choices[0].delta.content)
```

**نموذج الاستجابة**

```
I
I didn
I didn't
I didn't laugh after watching this video
I didn't laugh after watching this video. 
```

> لا يدعم نموذج Qwen-MT حاليًا وضع المخرجات المتدفقة التزايدية.

### **التدخل في المصطلحات**

إذا كان النص المصدر يحتوي على مصطلحات متخصصة كثيرة، فقد لا تقدم الشيفرة البرمجية في المثال البسيط ترجمة دقيقة لها. يمكنك ترجمة هذه المصطلحات مسبقًا وتزويد النموذج بها كمرجع:

**طريقة تعريف المصطلحات وتمريرها:**

1.  **تعريف مصفوفة المصطلحات**
    أنشئ مصفوفة JSON باسم `terms` تحتوي على مصطلحاتك. كل مصطلح هو كائن JSON يحتوي على المصطلح وترجمته:

    ```json
    {
        "source": "Term",
        "target": "Pre-translated term"
    }
    ```

2.  **تمرير المصفوفة**
    مرّر مصفوفة `terms` التي عرفتها في الخطوة الأولى إلى المُعامِل `translation_options`.

بعد تعريف المصطلحات وتمريرها، ارجع إلى الشيفرة البرمجية التالية للترجمة مع التدخل في المصطلحات.

**نموذج الطلب**

```python
import os
from openai import OpenAI

client = OpenAI(
        # إذا لم تكن متغيرات البيئة مهيأة، فاستبدل السطر التالي بـ: api_key="sk-xxx"
        api_key=os.getenv("DASHSCOPE_API_KEY"),
        base_url="https://dashscope-intl.aliyuncs.com/compatible-mode/v1",
    )
messages = [
      {
        "role": "user",
        "content": "而这套生物传感器运用了石墨烯这种新型材料，它的目标物是化学元素，敏锐的"嗅觉"让它能更深度、准确地体现身体健康状况。"
      }
    ]
translation_options = {
      "source_lang": "Chinese",
      "target_lang": "English",
      "terms": [
        {
          "source": "生物传感器",
          "target": "biological sensor"
        },
        {
          "source": "石墨烯",
          "target": "graphene"
        },
        {
          "source": "化学元素",
          "target": "chemical elements"
        },
        {
          "source": "身体健康状况",
          "target": "health status of the body"
        }
      ]
    }
    
completion = client.chat.completions.create(
    model="qwen-mt-turbo",  # استخدام qwen-mt-turbo كمثال، ويمكنك تغيير اسم النموذج حسب الحاجة
    messages=messages,
    extra_body={
        "translation_options": translation_options
    }
)
print(completion.choices[0].message.content)
```

**نموذج الاستجابة**

```
This biological sensor uses graphene, a new material, and its target is chemical elements. Its sensitive "nose" can more deeply and accurately reflect the health status of the body. 
```

### **ذاكرة الترجمة**

إذا كانت لديك أزواج لغوية قياسية وتحتاج إلى أن يسترشد النموذج بهذه الترجمات المعتمدة، فيمكنك استخدام خاصية ذاكرة الترجمة:

**لتعريف ذاكرة الترجمة وتمريرها:**

1.  **تعريف مصفوفة ذاكرة الترجمة**
    أنشئ مصفوفة JSON باسم `tm_list`. كل كائن JSON يحتوي على الجملة المصدر وما يقابلها من ترجمة بالصيغة التالية:
    
    ```json
    {
        "source": "Source sentence",
        "target": "Translated sentence"
    }
    ```

2.  **إدخال مصفوفة ذاكرة الترجمة**
    مرّر مصفوفة ذاكرة الترجمة `tm_list` التي عرفتها في الخطوة الأولى إلى المُعامِل `translation_options`.

بعد تعريف ذاكرة الترجمة وتمريرها، ارجع إلى الشيفرة البرمجية التالية للترجمة باستخدام ذاكرة الترجمة.

**نموذج الطلب**

```python
import os
from openai import OpenAI

client = OpenAI(
        # إذا لم تكن متغيرات البيئة مهيأة، فاستبدل السطر التالي بـ: api_key="sk-xxx"
        api_key=os.getenv("DASHSCOPE_API_KEY"),
        base_url="https://dashscope-intl.aliyuncs.com/compatible-mode/v1",
    )
messages = [
      {
        "role": "user",
        "content": "通过如下命令可以看出安装thrift的版本信息；"
      }
    ]
translation_options = {
      "source_lang": "Chinese",
      "target_lang": "English",
      "tm_list":[
          {"source": "您可以通过如下方式查看集群的内核版本信息:", "target": "You can use one of the following methods to query the engine version of a cluster:"},
          {"source": "我们云HBase的thrift环境是0.9.0,所以建议客户端的版本也为 0.9.0,可以从这里下载thrift的0.9.0 版本,下载的源码包我们后面会用到,这里需要先安装thrift编译环境,对于源码安装可以参考thrift官网;", "target": "The version of Thrift used by ApsaraDB for HBase is 0.9.0. Therefore, we recommend that you use Thrift 0.9.0 to create a client. Click here to download Thrift 0.9.0. The downloaded source code package will be used later. You must install the Thrift compiling environment first. For more information, see Thrift official website."},
          {"source": "您可以通过PyPI来安装SDK,安装命令如下:", "target": "You can run the following command in Python Package Index (PyPI) to install Elastic Container Instance SDK for Python:"}
      ]
    }
    
completion = client.chat.completions.create(
    model="qwen-mt-turbo",  # استخدام qwen-mt-turbo كمثال، ويمكنك تغيير اسم النموذج حسب الحاجة
    messages=messages,
    extra_body={
        "translation_options": translation_options
    }
)
print(completion.choices[0].message.content)
```

**نموذج الاستجابة**

```
You can use the following commands to check the version information of thrift installed; 
```

### **التوجيه حسب المجال**

إذا كنت تريد أن تتوافق الترجمة مع أسلوب مجال معين، كاللغة القانونية الرسمية أو اللغة غير الرسمية، فقدم وصفًا باللغة الطبيعية للمجال ليكون بمثابة توجيه (prompt) للنموذج.

*   يجب أن يكون التوجيه الخاص بالمجال باللغة الإنجليزية حاليًا.

مرّر توجيه المجال `domains` الذي عرفته عبر المُعامِل `translation_options`.

**نموذج الطلب**

```python
import os
from openai import OpenAI

client = OpenAI(
        # إذا لم تكن متغيرات البيئة مهيأة، فاستبدل السطر التالي بـ: api_key="sk-xxx"
        api_key=os.getenv("DASHSCOPE_API_KEY"),
        base_url="https://dashscope-intl.aliyuncs.com/compatible-mode/v1",
    )
messages = [
      {
        "role": "user",
        "content": "第二个SELECT语句返回一个数字，表示在没有LIMIT子句的情况下，第一个SELECT语句返回了多少行。"
      }
    ]
translation_options = {
      "source_lang": "Chinese",
      "target_lang": "English",
      "domains": "The sentence is from Alibaba Cloud IT domain. It mainly involves computer-related software development and usage methods, including many terms related to computer software and hardware. Pay attention to professional troubleshooting terminologies and sentence patterns when translating. Translate into this IT domain style."
    }
    
completion = client.chat.completions.create(
    model="qwen-mt-turbo",  # استخدام qwen-mt-turbo كمثال، ويمكنك تغيير اسم النموذج حسب الحاجة
    messages=messages,
    extra_body={
        "translation_options": translation_options
    }
)
print(completion.choices[0].message.content)
```

**نموذج الاستجابة**

```
The second SELECT statement returns a number that indicates how many rows were returned by the first SELECT statement without LIMIT clause. 
```

### **اللغات المدعومة**
<a name="supported-languages"></a>
فيما يلي اللغات المدعومة وأسماؤها الكاملة ورموزها اللغوية. يمكنك استخدام الاسم الكامل أو الرمز اللغوي لتحديد اللغات في الطلبات.